{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Postcode District     Make                  Variant Company/Private  \\\n",
      "0              BS16   TOYOTA          C-HR DESIGN HEV               C   \n",
      "1              BS16     SEAT  LEON SE DYNAMIC TSI EVO               C   \n",
      "2              BS16     SEAT  LEON SE DYNAMIC TSI EVO               C   \n",
      "3              BS16    SKODA           KAROQ SE L TSI               C   \n",
      "4              BS16  RENAULT   MEGANE ICONIC BLUE DCI               C   \n",
      "\n",
      "   Registrations  Number of Seats   Body Style  Year of 1st Reg   latitude  \\\n",
      "0             11                4  5 HATCHBACK             2020  51.486811   \n",
      "1             21                4  5 HATCHBACK             2021  51.486811   \n",
      "2             34                4  5 HATCHBACK             2021  51.486811   \n",
      "3             17                4       ESTATE             2021  51.486811   \n",
      "4             14                4       ESTATE             2021  51.486811   \n",
      "\n",
      "   longitude  \n",
      "0  -2.510027  \n",
      "1  -2.510027  \n",
      "2  -2.510027  \n",
      "3  -2.510027  \n",
      "4  -2.510027  \n",
      "The Column Header : ['Postcode District', 'Make', 'Variant', 'Company/Private', 'Registrations', 'Number of Seats', 'Body Style', 'Year of 1st Reg', 'latitude', 'longitude']\n",
      "      Make Postcode District  Company/Private  Registrations  Number of Seats  \\\n",
      "0   TOYOTA              BS16                0              1                4   \n",
      "1     SEAT              BS16                0             11                4   \n",
      "2     SEAT              BS16                0             24                4   \n",
      "3    SKODA              BS16                0              7                4   \n",
      "4  RENAULT              BS16                0              4                4   \n",
      "\n",
      "   Body Style   latitude  longitude  \n",
      "0           4  51.486811  -2.510027  \n",
      "1           4  51.486811  -2.510027  \n",
      "2           4  51.486811  -2.510027  \n",
      "3           7  51.486811  -2.510027  \n",
      "4           7  51.486811  -2.510027  \n",
      "      Make Postcode District  Company/Private  Registrations  Number of Seats  \\\n",
      "0   TOYOTA              BS16                0              1                4   \n",
      "1     SEAT              BS16                0             11                4   \n",
      "2     SEAT              BS16                0             24                4   \n",
      "3    SKODA              BS16                0              7                4   \n",
      "4  RENAULT              BS16                0              4                4   \n",
      "\n",
      "   Body Style   latitude  longitude  \n",
      "0           4  51.486811  -2.510027  \n",
      "1           4  51.486811  -2.510027  \n",
      "2           4  51.486811  -2.510027  \n",
      "3           7  51.486811  -2.510027  \n",
      "4           7  51.486811  -2.510027  \n",
      "    latitude  longitude  Number of Seats  Make  Postcode District  \\\n",
      "0  51.486811  -2.510027                4    71                119   \n",
      "1  51.486811  -2.510027                4    62                119   \n",
      "2  51.486811  -2.510027                4    62                119   \n",
      "3  51.486811  -2.510027                4    63                119   \n",
      "4  51.486811  -2.510027                4    58                119   \n",
      "\n",
      "   Company/Private  Registrations  Body Style  \n",
      "0                0              1           4  \n",
      "1                0             11           4  \n",
      "2                0             24           4  \n",
      "3                0              7           7  \n",
      "4                0              4           7  \n",
      "   Number of Seats  Body Style  Company/Private  Postcode District  Make\n",
      "0                4           4                0                119    71\n",
      "1                4           4                0                119    62\n",
      "2                4           4                0                119    62\n",
      "3                4           7                0                119    63\n",
      "4                4           7                0                119    58\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:          Registrations   R-squared (uncentered):                   0.222\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.222\n",
      "Method:                 Least Squares   F-statistic:                              2419.\n",
      "Date:                Tue, 16 Jan 2024   Prob (F-statistic):                        0.00\n",
      "Time:                        11:49:49   Log-Likelihood:                     -2.0829e+05\n",
      "No. Observations:               42375   AIC:                                  4.166e+05\n",
      "Df Residuals:                   42370   BIC:                                  4.166e+05\n",
      "Df Model:                           5                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "=====================================================================================\n",
      "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "Number of Seats       0.0113      0.019      0.604      0.546      -0.025       0.048\n",
      "Body Style            0.6995      0.047     14.912      0.000       0.608       0.791\n",
      "Company/Private      -5.7423      2.366     -2.427      0.015     -10.380      -1.105\n",
      "Postcode District     0.0124      0.000     28.046      0.000       0.012       0.013\n",
      "Make                  0.1168      0.006     20.716      0.000       0.106       0.128\n",
      "==============================================================================\n",
      "Omnibus:                    39540.521   Durbin-Watson:                   1.609\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          1681817.951\n",
      "Skew:                           4.561   Prob(JB):                         0.00\n",
      "Kurtosis:                      32.484   Cond. No.                     1.01e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[3] The condition number is large, 1.01e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "C:\\Users\\alvesd\\OneDrive - smmt.co.uk\\Desktop\\Diego_work_folder\\python\\33_Sales_Target_Region_Vehicle_Seats\n"
     ]
    },
    {
     "ename": "EOFError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mEOFError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 95\u001B[0m\n\u001B[0;32m     92\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mIPython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdisplay\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m display, HTML\n\u001B[0;32m     94\u001B[0m \u001B[38;5;66;03m# Load the data set and repalce the empty rows for NaN valeu\u001B[39;00m\n\u001B[1;32m---> 95\u001B[0m parc_cluster \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_excel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     96\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mC:\u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;124;43mUsers\u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;124;43malvesd\u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;124;43mOneDrive - smmt.co.uk\u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;124;43mDesktop\u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;124;43mDiego_work_folder\u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;124;43mpython\u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;124;43m33_Sales_Target_Region_Vehicle_Seats\u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;124;43mParc_Data.xlsx\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     97\u001B[0m \u001B[38;5;66;03m# Define colours:\u001B[39;00m\n\u001B[0;32m     98\u001B[0m cols \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m#e6194b\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m#3cb44b\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m#ffe119\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m#4363d8\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m#f58231\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m#911eb4\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m#46f0f0\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m#f032e6\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m#bcf60c\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m#fabebe\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m     99\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m#008080\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m#e6beff\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m#9a6324\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m#fffac8\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m#800000\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m#aaffc3\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m#808000\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m#ffd8b1\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m#000075\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m    100\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m#808080\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m10\u001B[39m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:486\u001B[0m, in \u001B[0;36mread_excel\u001B[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend)\u001B[0m\n\u001B[0;32m    480\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    481\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEngine should not be specified when passing \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    482\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124man ExcelFile - ExcelFile already has the engine set\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    483\u001B[0m     )\n\u001B[0;32m    485\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 486\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[43mio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparse\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    487\u001B[0m \u001B[43m        \u001B[49m\u001B[43msheet_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msheet_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    488\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    489\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnames\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnames\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    490\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindex_col\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex_col\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    491\u001B[0m \u001B[43m        \u001B[49m\u001B[43musecols\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43musecols\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    492\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    493\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconverters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconverters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    494\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrue_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrue_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    495\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfalse_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfalse_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    496\u001B[0m \u001B[43m        \u001B[49m\u001B[43mskiprows\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mskiprows\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    497\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnrows\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnrows\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    498\u001B[0m \u001B[43m        \u001B[49m\u001B[43mna_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mna_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    499\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkeep_default_na\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeep_default_na\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[43mna_filter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mna_filter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    501\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    502\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparse_dates\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparse_dates\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    503\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdate_parser\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdate_parser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    504\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdate_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdate_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    505\u001B[0m \u001B[43m        \u001B[49m\u001B[43mthousands\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mthousands\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    506\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdecimal\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecimal\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    507\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcomment\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcomment\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    508\u001B[0m \u001B[43m        \u001B[49m\u001B[43mskipfooter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mskipfooter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    509\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype_backend\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype_backend\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    510\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    511\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    512\u001B[0m     \u001B[38;5;66;03m# make sure to close opened file handles\u001B[39;00m\n\u001B[0;32m    513\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m should_close:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1551\u001B[0m, in \u001B[0;36mExcelFile.parse\u001B[1;34m(self, sheet_name, header, names, index_col, usecols, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, date_format, thousands, comment, skipfooter, dtype_backend, **kwds)\u001B[0m\n\u001B[0;32m   1518\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mparse\u001B[39m(\n\u001B[0;32m   1519\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   1520\u001B[0m     sheet_name: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m|\u001B[39m \u001B[38;5;28mint\u001B[39m \u001B[38;5;241m|\u001B[39m \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mint\u001B[39m] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mstr\u001B[39m] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1538\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds,\n\u001B[0;32m   1539\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m \u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, DataFrame] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mint\u001B[39m, DataFrame]:\n\u001B[0;32m   1540\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1541\u001B[0m \u001B[38;5;124;03m    Parse specified sheet(s) into a DataFrame.\u001B[39;00m\n\u001B[0;32m   1542\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1549\u001B[0m \u001B[38;5;124;03m        DataFrame from the passed in Excel file.\u001B[39;00m\n\u001B[0;32m   1550\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_reader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparse\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1552\u001B[0m \u001B[43m        \u001B[49m\u001B[43msheet_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msheet_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1553\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1554\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnames\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnames\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1555\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindex_col\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex_col\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1556\u001B[0m \u001B[43m        \u001B[49m\u001B[43musecols\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43musecols\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1557\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconverters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconverters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1558\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrue_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrue_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1559\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfalse_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfalse_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1560\u001B[0m \u001B[43m        \u001B[49m\u001B[43mskiprows\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mskiprows\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1561\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnrows\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnrows\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1562\u001B[0m \u001B[43m        \u001B[49m\u001B[43mna_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mna_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1563\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparse_dates\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparse_dates\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1564\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdate_parser\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdate_parser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1565\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdate_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdate_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1566\u001B[0m \u001B[43m        \u001B[49m\u001B[43mthousands\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mthousands\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1567\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcomment\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcomment\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1568\u001B[0m \u001B[43m        \u001B[49m\u001B[43mskipfooter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mskipfooter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1569\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype_backend\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype_backend\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1570\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1571\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:751\u001B[0m, in \u001B[0;36mBaseExcelReader.parse\u001B[1;34m(self, sheet_name, header, names, index_col, usecols, dtype, true_values, false_values, skiprows, nrows, na_values, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, dtype_backend, **kwds)\u001B[0m\n\u001B[0;32m    748\u001B[0m     sheet \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_sheet_by_index(asheetname)\n\u001B[0;32m    750\u001B[0m file_rows_needed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_calc_rows(header, index_col, skiprows, nrows)\n\u001B[1;32m--> 751\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_sheet_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43msheet\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfile_rows_needed\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    752\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(sheet, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclose\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    753\u001B[0m     \u001B[38;5;66;03m# pyxlsb opens two TemporaryFiles\u001B[39;00m\n\u001B[0;32m    754\u001B[0m     sheet\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:602\u001B[0m, in \u001B[0;36mOpenpyxlReader.get_sheet_data\u001B[1;34m(self, sheet, file_rows_needed)\u001B[0m\n\u001B[0;32m    600\u001B[0m data: \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mlist\u001B[39m[Scalar]] \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m    601\u001B[0m last_row_with_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[1;32m--> 602\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m row_number, row \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(sheet\u001B[38;5;241m.\u001B[39mrows):\n\u001B[0;32m    603\u001B[0m     converted_row \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_convert_cell(cell) \u001B[38;5;28;01mfor\u001B[39;00m cell \u001B[38;5;129;01min\u001B[39;00m row]\n\u001B[0;32m    604\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m converted_row \u001B[38;5;129;01mand\u001B[39;00m converted_row[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    605\u001B[0m         \u001B[38;5;66;03m# trim trailing empty elements\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:81\u001B[0m, in \u001B[0;36mReadOnlyWorksheet._cells_by_row\u001B[1;34m(self, min_col, min_row, max_col, max_row, values_only)\u001B[0m\n\u001B[0;32m     77\u001B[0m src \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_source()\n\u001B[0;32m     78\u001B[0m parser \u001B[38;5;241m=\u001B[39m WorkSheetParser(src, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shared_strings,\n\u001B[0;32m     79\u001B[0m                          data_only\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparent\u001B[38;5;241m.\u001B[39mdata_only, epoch\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparent\u001B[38;5;241m.\u001B[39mepoch,\n\u001B[0;32m     80\u001B[0m                          date_formats\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparent\u001B[38;5;241m.\u001B[39m_date_formats)\n\u001B[1;32m---> 81\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m idx, row \u001B[38;5;129;01min\u001B[39;00m parser\u001B[38;5;241m.\u001B[39mparse():\n\u001B[0;32m     82\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m max_row \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m idx \u001B[38;5;241m>\u001B[39m max_row:\n\u001B[0;32m     83\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openpyxl\\worksheet\\_reader.py:156\u001B[0m, in \u001B[0;36mWorkSheetParser.parse\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    137\u001B[0m properties \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    138\u001B[0m     PRINT_TAG: (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprint_options\u001B[39m\u001B[38;5;124m'\u001B[39m, PrintOptions),\n\u001B[0;32m    139\u001B[0m     MARGINS_TAG: (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpage_margins\u001B[39m\u001B[38;5;124m'\u001B[39m, PageMargins),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    151\u001B[0m \n\u001B[0;32m    152\u001B[0m }\n\u001B[0;32m    154\u001B[0m it \u001B[38;5;241m=\u001B[39m iterparse(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msource) \u001B[38;5;66;03m# add a finaliser to close the source when this becomes possible\u001B[39;00m\n\u001B[1;32m--> 156\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _, element \u001B[38;5;129;01min\u001B[39;00m it:\n\u001B[0;32m    157\u001B[0m     tag_name \u001B[38;5;241m=\u001B[39m element\u001B[38;5;241m.\u001B[39mtag\n\u001B[0;32m    158\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m tag_name \u001B[38;5;129;01min\u001B[39;00m dispatcher:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\xml\\etree\\ElementTree.py:1251\u001B[0m, in \u001B[0;36miterparse.<locals>.iterator\u001B[1;34m(source)\u001B[0m\n\u001B[0;32m   1249\u001B[0m \u001B[38;5;28;01myield from\u001B[39;00m pullparser\u001B[38;5;241m.\u001B[39mread_events()\n\u001B[0;32m   1250\u001B[0m \u001B[38;5;66;03m# load event buffer\u001B[39;00m\n\u001B[1;32m-> 1251\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[43msource\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m16\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1024\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1252\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m data:\n\u001B[0;32m   1253\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\zipfile.py:955\u001B[0m, in \u001B[0;36mZipExtFile.read\u001B[1;34m(self, n)\u001B[0m\n\u001B[0;32m    953\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_offset \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m    954\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m n \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_eof:\n\u001B[1;32m--> 955\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_read1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    956\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m n \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mlen\u001B[39m(data):\n\u001B[0;32m    957\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_readbuffer \u001B[38;5;241m=\u001B[39m data\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\zipfile.py:1023\u001B[0m, in \u001B[0;36mZipExtFile._read1\u001B[1;34m(self, n)\u001B[0m\n\u001B[0;32m   1021\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_decompressor\u001B[38;5;241m.\u001B[39munconsumed_tail\n\u001B[0;32m   1022\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m n \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mlen\u001B[39m(data):\n\u001B[1;32m-> 1023\u001B[0m         data \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_read2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1024\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1025\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_read2(n)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\zipfile.py:1058\u001B[0m, in \u001B[0;36mZipExtFile._read2\u001B[1;34m(self, n)\u001B[0m\n\u001B[0;32m   1056\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compress_left \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(data)\n\u001B[0;32m   1057\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m data:\n\u001B[1;32m-> 1058\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mEOFError\u001B[39;00m\n\u001B[0;32m   1060\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_decrypter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1061\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_decrypter(data)\n",
      "\u001B[1;31mEOFError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import webbrowser\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib_inline.config import InlineBackend\n",
    "\n",
    "np.random.seed(0)\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "scale = StandardScaler()\n",
    "# Load the data set and repalce the empty rows for NaN valeu\n",
    "parc = pd.read_excel(\n",
    "    \"C:\\\\Users\\\\alvesd\\\\OneDrive - smmt.co.uk\\\\Desktop\\\\Diego_work_folder\\\\python\\\\33_Sales_Target_Region_Vehicle_Seats\\\\Parc_Data.xlsx\")\n",
    "# Print Headers\n",
    "print(parc.head(5))\n",
    "# Print columns headers:\n",
    "column_headers = list(parc.columns.values)\n",
    "print(\"The Column Header :\", column_headers)\n",
    "parc = parc[\n",
    "    ['Postcode District', 'Make', 'Company/Private', 'Registrations', 'Number of Seats', 'Body Style', 'latitude',\n",
    "     'longitude']]\n",
    "# Turn Texts to numbers\n",
    "le = LabelEncoder()\n",
    "\n",
    "ignore = ['latitude', 'longitude', 'Postcode District', 'Make', 'Number of Seats']\n",
    "\n",
    "parc = (parc.set_index(ignore, append=True)\n",
    "        .apply(le.fit_transform)\n",
    "        .reset_index(ignore)\n",
    "        )\n",
    "parc = parc[\n",
    "    ['Make', 'Postcode District', 'Company/Private', 'Registrations', 'Number of Seats', 'Body Style', 'latitude',\n",
    "     'longitude']]\n",
    "print(parc.head())\n",
    "# Save numeric data to file:\n",
    "parc.to_excel(\n",
    "    'C:\\\\Users\\\\alvesd\\\\OneDrive - smmt.co.uk\\\\Desktop\\\\Diego_work_folder\\\\python\\\\33_Sales_Target_Region_Vehicle_Seats\\\\Parc_Numeric_Data_1.xlsx',\n",
    "    index=False)\n",
    "filtered_data = parc[parc[\"Number of Seats\"] == 2]\n",
    "filtered_data.iloc[0:5, 1:7]\n",
    "print(parc.head())\n",
    "# Load the data set and repalce the empty rows for NaN valeu\n",
    "parc_regression = pd.read_excel(\n",
    "    \"C:\\\\Users\\\\alvesd\\\\OneDrive - smmt.co.uk\\\\Desktop\\\\Diego_work_folder\\\\python\\\\33_Sales_Target_Region_Vehicle_Seats\\\\Parc_Numeric_Data_1.xlsx\")\n",
    "# Turn Texts to numbers\n",
    "le = LabelEncoder()\n",
    "\n",
    "ignore = ['latitude', 'longitude', 'Number of Seats']\n",
    "\n",
    "parc_regression = (parc_regression.set_index(ignore, append=True)\n",
    "                   .apply(le.fit_transform)\n",
    "                   .reset_index(ignore)\n",
    "                   )\n",
    "print(parc_regression.head())\n",
    "# Prediction\n",
    "predictors = parc_regression[['Number of Seats', 'Body Style', 'Company/Private', 'Postcode District', 'Make']]\n",
    "target = parc_regression['Registrations']\n",
    "print(predictors.head())\n",
    "predictors = pd.get_dummies(predictors)\n",
    "regression_model = sm.OLS(target, predictors)\n",
    "summary_table = regression_model.fit()\n",
    "print(summary_table.summary())\n",
    "# Clustering Geolocation Data in Python using DBSCAN and K-Means\n",
    "import os\n",
    "\n",
    "print(os.path.abspath(\".\"))\n",
    "from collections import defaultdict\n",
    "from ipywidgets import interactive\n",
    "import hdbscan\n",
    "import folium\n",
    "import re\n",
    "import matplotlib\n",
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'svg'\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import folium\n",
    "from folium import plugins\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Load the data set and repalce the empty rows for NaN valeu\n",
    "parc_cluster = pd.read_excel(\n",
    "    \"C:\\\\Users\\\\alvesd\\\\OneDrive - smmt.co.uk\\\\Desktop\\\\Diego_work_folder\\\\python\\\\33_Sales_Target_Region_Vehicle_Seats\\\\Parc_Data.xlsx\")\n",
    "# Define colours:\n",
    "cols = ['#e6194b', '#3cb44b', '#ffe119', '#4363d8', '#f58231', '#911eb4', '#46f0f0', '#f032e6', '#bcf60c', '#fabebe',\n",
    "        '#008080', '#e6beff', '#9a6324', '#fffac8', '#800000', '#aaffc3', '#808000', '#ffd8b1', '#000075',\n",
    "        '#808080'] * 10\n",
    "print(parc_cluster.head())\n",
    "# Drop the Null and duplicates\n",
    "print(parc_cluster.duplicated(subset=['longitude', 'latitude']).values.any())\n",
    "\n",
    "print(parc_cluster.isna().values.any())\n",
    "\n",
    "print(f'Before (Nulls and Duplicates) \\t:\\tParc_cluster.shape = {parc_cluster.shape}')\n",
    "parc_cluster.dropna(inplace=True)\n",
    "parc_cluster.drop_duplicates(subset=['longitude', 'latitude'], keep='first', inplace=True)\n",
    "print(f'After (Nulls and Duplicates) \\t:\\tParc_cluster.shape = {parc_cluster.shape}')\n",
    "# Plot the points:\n",
    "X = np.array(parc_cluster[['longitude', 'latitude']], dtype='float64')\n",
    "plt.scatter(X[:, 0], X[:, 1], alpha=0.2, s=50)\n",
    "plt.show()\n",
    "m = folium.Map(location=[parc_cluster['latitude'].mean(), parc_cluster['longitude'].mean()], zoom_start=7)\n",
    "\n",
    "for _, row in parc_cluster.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row.latitude, row.longitude],\n",
    "        radius=5,\n",
    "        popup=re.sub(r'[^a-zA-Z]+', '', row.Make),\n",
    "        color='#1787FE',\n",
    "        fill=True,\n",
    "        fill_color='#1787FE').add_to(m)\n",
    "m.save('seats.html')\n",
    "# Clustering Strength\n",
    "X_blobs, _ = make_blobs(n_samples=2653, centers=10,\n",
    "                        n_features=2, cluster_std=0.5, random_state=4)\n",
    "plt.scatter(X_blobs[:, 0], X_blobs[:, 1], alpha=0.2)\n",
    "plt.show()\n",
    "\n",
    "# Load the data set and repalce the empty rows for NaN valeu\n",
    "Parc_Numeric_Data = pd.read_excel(\n",
    "    \"C:\\\\Users\\\\alvesd\\\\OneDrive - smmt.co.uk\\\\Desktop\\\\Diego_work_folder\\\\python\\\\33_Sales_Target_Region_Vehicle_Seats\\\\Parc_Numeric_Data_1.xlsx\")\n",
    "filtered_data = Parc_Numeric_Data[Parc_Numeric_Data[\"Number of Seats\"] == 2]\n",
    "filtered_data.iloc[0:5, 1:7]\n",
    "# Drop the Null and duplicates\n",
    "print(Parc_Numeric_Data.duplicated(subset=['longitude', 'latitude']).values.any())\n",
    "print(Parc_Numeric_Data.isna().values.any())\n",
    "filtered_data = Parc_Numeric_Data[Parc_Numeric_Data[\"Number of Seats\"] == 2]\n",
    "filtered_data.iloc[0:5, 1:7]\n",
    "print(f'Before (Nulls and Duplicates) \\t:\\tParc_cluster.shape = {Parc_Numeric_Data.shape}')\n",
    "Parc_Numeric_Data.dropna(inplace=True)\n",
    "Parc_Numeric_Data.drop_duplicates(subset=['longitude', 'latitude'], keep='last', inplace=True)\n",
    "#Parc_Numeric_Data.drop_duplicates(subset=['longitude', 'latitude'], keep='first', inplace=True)\n",
    "print(f'After (Nulls and Duplicates) \\t:\\tParc_cluster.shape = {Parc_Numeric_Data.shape}')\n",
    "Parc_Numeric_Data.to_excel(\n",
    "    'C:\\\\Users\\\\alvesd\\\\OneDrive - smmt.co.uk\\\\Desktop\\\\Diego_work_folder\\\\python\\\\33_Sales_Target_Region_Vehicle_Seats\\\\Parc_Numeric_Data_2.xlsx',\n",
    "    index=False)\n",
    "Parc_Numeric_Data = pd.read_excel(\n",
    "    'C:\\\\Users\\\\alvesd\\\\OneDrive - smmt.co.uk\\\\Desktop\\\\Diego_work_folder\\\\python\\\\33_Sales_Target_Region_Vehicle_Seats\\\\Parc_Numeric_Data_2.xlsx')\n",
    "#Parc_Numeric_Data.drop_duplicates(subset=['longitude', 'latitude'], keep='first', inplace=True)\n",
    "filtered_data = Parc_Numeric_Data[Parc_Numeric_Data[\"Number of Seats\"] == 2]\n",
    "filtered_data.iloc[0:5, 1:9]\n",
    "class_predictions = Parc_Numeric_Data['Company/Private']\n",
    "unique_clusters = np.unique(class_predictions)\n",
    "for unique_clusters in unique_clusters:\n",
    "    X = X_blobs[class_predictions == unique_clusters]\n",
    "    plt.scatter(X[:, 0], X[:, 1], alpha=0.2, c=cols[unique_clusters])\n",
    "    plt.show()\n",
    "\n",
    "print(silhouette_score(X_blobs, class_predictions))\n",
    "class_predictions = Parc_Numeric_Data['Body Style']\n",
    "unique_clusters = np.unique(class_predictions)\n",
    "for unique_clusters in unique_clusters:\n",
    "    X = X_blobs[class_predictions == unique_clusters]\n",
    "    plt.scatter(X[:, 0], X[:, 1], alpha=0.2, c=cols[unique_clusters])\n",
    "    plt.show()\n",
    "\n",
    "print(silhouette_score(X_blobs, class_predictions))\n",
    "X_blobs, _ = make_blobs(n_samples=1000, centers=50,\n",
    "                        n_features=2, cluster_std=1, random_state=4)\n",
    "data = defaultdict(dict)\n",
    "for x in range(1, 21):\n",
    "    model = KMeans(n_clusters=3, random_state=17,\n",
    "                   max_iter=x, n_init=1).fit(X_blobs)\n",
    "\n",
    "    data[x]['class_predictions'] = model.predict(X_blobs)\n",
    "    data[x]['centroids'] = model.cluster_centers_\n",
    "    data[x]['unique_classes'] = np.unique(class_predictions)\n",
    "\n",
    "\n",
    "def f(x):\n",
    "    class_predictions = data[x]['class_predictions']\n",
    "    centroids = data[x]['centroids']\n",
    "    unique_classes = data[x]['unique_classes']\n",
    "    for unique_class in unique_classes:\n",
    "        plt.scatter(X_blobs[class_predictions == unique_class][:, 0],\n",
    "                    X_blobs[class_predictions == unique_class][:, 1],\n",
    "                    alpha=0.3, c=cols[unique_class])\n",
    "    plt.scatter(centroids[:, 0], centroids[:, 1], s=200, c='#000000', marker='v')\n",
    "    plt.ylim([-15, 15]);\n",
    "    plt.xlim([-15, 15])\n",
    "    plt.title('How K-Means Clusters')\n",
    "\n",
    "\n",
    "interactive_plot = interactive(f, x=(1, 20))\n",
    "output = interactive_plot.children[-1]\n",
    "output.layout.height = '350px'\n",
    "interactive_plot\n",
    "X = np.array(Parc_Numeric_Data[['longitude', 'latitude']], dtype='float64')\n",
    "k = 70\n",
    "model = KMeans(n_clusters=k, random_state=17).fit(X)\n",
    "class_predictions = model.predict(X)\n",
    "Parc_Numeric_Data[f'CLUSTER_kmeans{k}'] = class_predictions\n",
    "# Save numeric data to file:\n",
    "Parc_Numeric_Data.to_excel(\n",
    "    'C:\\\\Users\\\\alvesd\\\\OneDrive - smmt.co.uk\\\\Desktop\\\\Diego_work_folder\\\\python\\\\33_Sales_Target_Region_Vehicle_Seats\\\\Parc_Numeric_Data_1.xlsx',\n",
    "    index=False)\n",
    "filtered_data = Parc_Numeric_Data[Parc_Numeric_Data[\"Number of Seats\"] == 2]\n",
    "filtered_data.iloc[0:5, 1:9]\n",
    "Parc_Numeric_Data_1 = pd.read_excel(\n",
    "    'C:\\\\Users\\\\alvesd\\\\OneDrive - smmt.co.uk\\\\Desktop\\\\Diego_work_folder\\\\python\\\\33_Sales_Target_Region_Vehicle_Seats\\\\Parc_Numeric_Data_1.xlsx')\n",
    "Parc_Numeric_Data = Parc_Numeric_Data_1.dropna()\n",
    "Parc_Numeric_Data = Parc_Numeric_Data.reset_index(drop=True)\n",
    "print(Parc_Numeric_Data.head())\n",
    "filtered_data = Parc_Numeric_Data[Parc_Numeric_Data[\"Number of Seats\"] == 2]\n",
    "filtered_data.iloc[0:5, 1:7]\n",
    "Parc_Numeric_Data = Parc_Numeric_Data[['Make', 'Number of Seats', 'latitude', 'longitude']]\n",
    "print(Parc_Numeric_Data.head())\n",
    "# Clustering Analysis: https://medium.com/codex/clustering-geographic-data-on-an-interactive-map-in-python-60a5d13d6452\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial import ConvexHull\n",
    "import folium\n",
    "\n",
    "X = Parc_Numeric_Data.iloc[:, 1:4].values\n",
    "# Using the elbow method to find the optimal number of clusters\n",
    "wcss = []\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42)\n",
    "    kmeans.fit(X)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "plt.plot(range(1, 11), wcss)\n",
    "plt.title('The Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()\n",
    "# Training the K-Means model regarding your elbow method or business logic groups\n",
    "kmeans = KMeans(n_clusters=4, init='k-means++', random_state=42)\n",
    "y_kmeans = kmeans.fit_predict(X)\n",
    "# Map data back to df\n",
    "Parc_Numeric_Data['cluster'] = y_kmeans + 1  # to step up to group 0 to 4\n",
    "print(Parc_Numeric_Data.head())\n",
    "# Save numeric data to file:\n",
    "Parc_Numeric_Data.to_excel(\n",
    "    'C:\\\\Users\\\\alvesd\\\\OneDrive - smmt.co.uk\\\\Desktop\\\\Diego_work_folder\\\\python\\\\33_Sales_Target_Region_Vehicle_Seats\\\\Parc_Numeric_Data_1.xlsx',\n",
    "    index=False)\n",
    "# Plot data to map\n",
    "# Create the map object called m which is the base layer of the map\n",
    "m = folium.Map(location=[Parc_Numeric_Data['latitude'].mean(), Parc_Numeric_Data['longitude'].mean()],\n",
    "               tiles='CartoDB positron',\n",
    "               zoom_start=7)\n",
    "# Create layers based on your clustering groups\n",
    "layer1 = folium.FeatureGroup(name= '<u><b>Cluster 1</b></u>',show= True)\n",
    "m.add_child(layer1)\n",
    "layer2 = folium.FeatureGroup(name= '<u><b>Cluster 2</b></u>',show= True)\n",
    "m.add_child(layer2)\n",
    "layer3 = folium.FeatureGroup(name= '<u><b>Cluster 3</b></u>',show= True)\n",
    "m.add_child(layer3)\n",
    "layer4 = folium.FeatureGroup(name= '<u><b>Cluster 4</b></u>',show= True)\n",
    "m.add_child(layer4)\n",
    "#draw marker class for each group by adding CSS class\n",
    "my_symbol_css_class = \"\"\" <style>\n",
    ".fa-g1:before {\n",
    "    font-family: Arial; \n",
    "    font-weight: bold;\n",
    "    font-size: 12px;\n",
    "    color: black;\n",
    "    background-color:white;\n",
    "    border-radius: 10px; \n",
    "    white-space: pre;\n",
    "    content: ' G<=1 ';\n",
    "    }\n",
    ".fa-g2:before {\n",
    "    font-family: Arial; \n",
    "    font-weight: bold;\n",
    "    font-size: 12px;\n",
    "    color: black;\n",
    "    background-color:white;\n",
    "    border-radius: 10px; \n",
    "    white-space: pre;\n",
    "    content: ' G=2 ';\n",
    "    }\n",
    ".fa-g3:before {\n",
    "    font-family: Arial; \n",
    "    font-weight: bold;\n",
    "    font-size: 12px;\n",
    "    color: black;\n",
    "    background-color:white;\n",
    "    border-radius: 10px; \n",
    "    white-space: pre;\n",
    "    content: ' G=3 ';\n",
    "    }\n",
    ".fa-g4:before {\n",
    "    font-family: Arial; \n",
    "    font-weight: bold;\n",
    "    font-size: 12px;\n",
    "    color: black;\n",
    "    background-color:white;\n",
    "    border-radius: 10px; \n",
    "    white-space: pre;\n",
    "    content: ' G>=4 ';\n",
    "    }\n",
    ".fa-g1bad:before {\n",
    "    font-family: Arial; \n",
    "    font-weight: bold;\n",
    "    font-size: 12px;\n",
    "    color: black;\n",
    "    background-color:white;\n",
    "    border-radius: 10px; \n",
    "    white-space: pre;\n",
    "    content: ' G<=1 ';\n",
    "    }\n",
    ".fa-g2bad:before {\n",
    "    font-family: Arial; \n",
    "    font-weight: bold;\n",
    "    font-size: 12px;\n",
    "    color: black;\n",
    "    background-color:white;\n",
    "    border-radius: 10px; \n",
    "    white-space: pre;\n",
    "    content: ' G=2 ';\n",
    "    }\n",
    ".fa-g3bad:before {\n",
    "    font-family: Arial; \n",
    "    font-weight: bold;\n",
    "    font-size: 12px;\n",
    "    color: black;\n",
    "    background-color:white;\n",
    "    border-radius: 10px; \n",
    "    white-space: pre;\n",
    "    content: ' G=3 ';\n",
    "    }\n",
    ".fa-g4bad:before {\n",
    "    font-family: Arial; \n",
    "    font-weight: bold;\n",
    "    font-size: 12px;\n",
    "    color: black;\n",
    "    background-color:white;\n",
    "    border-radius: 10px; \n",
    "    white-space: pre;\n",
    "    content: ' G>=4 ';\n",
    "    }\n",
    "</style>\n",
    "\"\"\"\n",
    "# the below is just add above  CSS class to folium root map      \n",
    "m.get_root().html.add_child(folium.Element(my_symbol_css_class))\n",
    "# then we just create marker and specific your css class in icon like below\n",
    "for index, row in Parc_Numeric_Data.iterrows():\n",
    "    if row['cluster'] == 1 and row['Number of Seats'] == 2:\n",
    "        color = 'black'\n",
    "        fa_symbol = 'fa-g1'\n",
    "        lay = layer1\n",
    "    elif row['cluster'] == 1 and row['Number of Seats'] == 2:\n",
    "        color = 'black'\n",
    "        fa_symbol = 'fa-g1bad'\n",
    "        lay = layer1\n",
    "    elif row['cluster'] == 2 and row['Number of Seats'] == 2:\n",
    "        color = 'purple'\n",
    "        fa_symbol = 'fa-g2'\n",
    "        lay = layer2\n",
    "    elif row['cluster'] == 2 and row['Number of Seats'] == 2:\n",
    "        color = 'purple'\n",
    "        fa_symbol = 'fa-g2bad'\n",
    "        lay = layer2\n",
    "    elif row['cluster'] == 3 and row['Number of Seats'] == 2:\n",
    "        color = 'orange'\n",
    "        fa_symbol = 'fa-g3'\n",
    "        lay = layer3\n",
    "    elif row['cluster'] == 3 and row['Number of Seats'] == 2:\n",
    "        color = 'orange'\n",
    "        fa_symbol = 'fa-g3bad'\n",
    "        lay = layer3\n",
    "    elif row['cluster'] == 4 and row['Number of Seats'] == 2:\n",
    "        color = 'blue'\n",
    "        fa_symbol = 'fa-g4'\n",
    "        lay = layer4\n",
    "        \n",
    "    folium.Marker(\n",
    "        location=[row['latitude'], row['longitude']],\n",
    "        title = row['Make']+ ' Number of Seats: {}'.format(str(row['Number of Seats'])),\n",
    "        popup = row['Make']+ ' Number of Seats: {}'.format(str(row['Number of Seats'])),\n",
    "        icon= folium.Icon(color=color, icon=fa_symbol, prefix='fa')).add_to(lay)\n",
    "    \n",
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "#draw cluster each group\n",
    "#flat line to group path\n",
    "#prepare layer and color for each group\n",
    "layer_list = [layer1, layer2, layer3, layer4]\n",
    "color_list = ['black', 'purple', 'orange', 'blue']\n",
    "for g in Parc_Numeric_Data['cluster'].unique():\n",
    "    # this part we apply ConvexHull theory to find the boundary of each group\n",
    "    # first, we have to cut the lat lon in each group \n",
    "    latlon_cut = Parc_Numeric_Data[Parc_Numeric_Data['cluster'] == g].iloc[:, 1:3]\n",
    "    # second, scipy already provides  the great function for ConvexHull\n",
    "    # we just throw our dataframe with lat lon in this function\n",
    "    hull = ConvexHull(latlon_cut.values)\n",
    "    # and with magic, we can have new lat lon boundary of each group\n",
    "    Lat = latlon_cut.values[hull.vertices, 0]\n",
    "    Long = latlon_cut.values[hull.vertices, 1]\n",
    "    # the we create dataframe boundary and convert it to list of lat lon \n",
    "    # for plotting polygon in folium\n",
    "    cluster = pd.DataFrame({'latitude': Lat, 'longitude': Long})\n",
    "    area = list(zip(cluster['latitude'], cluster['longitude']))\n",
    "    # plot polygon\n",
    "    list_index = g - 1  # minus 1 to get the same index \n",
    "    lay_cluster = layer_list[list_index]\n",
    "    folium.Polygon(locations=area,\n",
    "                   color=color_list[list_index],\n",
    "                   weight=2,\n",
    "                   fill=True,\n",
    "                   fill_opacity=0.1,\n",
    "                   opacity=0.8).add_to(lay_cluster)\n",
    "\n",
    "# to let the map have selectd layer1 layer2 you created\n",
    "folium.LayerControl(collapsed=False, position='bottomright').add_to(m)\n",
    "# save it to html then we can send the file to our colleagues\n",
    "m.save(\n",
    "    'C:\\\\Users\\\\alvesd\\\\OneDrive - smmt.co.uk\\\\Desktop\\\\Diego_work_folder\\\\python\\\\33_Sales_Target_Region_Vehicle_Seats\\\\Tillett.html')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T11:49:52.853300Z",
     "start_time": "2024-01-16T11:49:39.711675Z"
    }
   },
   "id": "afc4079d4ec9810"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Done up to here!!!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df62a958c626d106"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
